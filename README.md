# GGADFormer

GGADFormer 是一个基于图 Transformer 和图社区检测的图异常检测框架，专门用于识别图中的异常节点。该方法结合了Transformer的注意力机制、图神经网络的特征提取能力以及社区检测的结构信息，实现了高效的半监督图异常检测。

# 核心思想

GGADFormer的主要创新在于：
1. **多尺度特征融合**：结合节点原始特征、邻居传播特征和社区嵌入特征
2. **注意力驱动的异常生成**：使用Transformer注意力机制指导异常样本的生成
3. **社区引导学习**：利用社区结构信息增强模型对图结构的理解
4. **对比学习框架**：通过对比学习区分正常节点和异常节点

# 方法架构

## 整体框架

GGADFormer 的整体架构包含以下主要组件：输入图经过特征预处理后，进入社区检测模块学习结构信息，然后通过图Transformer编码器进行特征融合和表示学习，接着由异常生成器创建合成异常样本，最后通过判别器输出异常检测结果。

## 详细组件分析

### 特征预处理模块

特征预处理模块是GGADFormer的入口组件，负责将原始图数据转换为模型可处理的标准化格式。该模块首先对节点特征矩阵进行行归一化处理，消除不同特征维度之间的尺度差异，确保所有特征在相同的数值范围内。然后对邻接矩阵进行对称归一化处理，使用度矩阵的逆平方根对邻接矩阵进行变换，提高数值稳定性并避免梯度爆炸或消失问题。最后通过多跳特征传播机制，将节点的k阶邻居信息聚合到中心节点，形成包含局部结构信息的增强特征表示。

该模块的核心价值在于确保输入数据的数值稳定性，通过多跳传播捕获节点的k阶邻居信息来增强特征表达能力，为后续的Transformer编码器提供高质量的输入特征。特征归一化消除了不同特征维度的量纲差异，邻接矩阵归一化提高了图卷积操作的数值稳定性，而多跳传播则扩展了节点的感受野，使模型能够捕获更丰富的局部结构信息。

### 社区检测模块

社区检测模块是GGADFormer的核心创新组件之一，专门负责学习图的社区结构信息并为异常检测提供结构层面的指导。该模块基于模块度理论，首先计算图的模块度矩阵，该矩阵量化了节点间的社区归属关系。模块度矩阵的计算公式为B_ij = A_ij - (k_i * k_j) / (2m)，其中A_ij是邻接矩阵元素，k_i是节点i的度，m是总边数。这个公式衡量了实际连接与随机连接之间的差异，能够有效识别社区结构。

然后，该模块使用自编码器架构对模块度矩阵进行编码和解码。编码器将模块度矩阵B转换为低维的社区嵌入H，解码器则试图从社区嵌入重构原始的模块度矩阵。通过最小化重构误差，模型学习到了能够保留社区结构信息的紧凑表示。这种设计使得社区嵌入H不仅捕获了节点的社区归属信息，还保留了社区间的结构关系。

该模块的重要意义在于为异常检测提供了结构层面的先验知识。在图中，异常节点往往表现出与社区结构不符的连接模式，例如连接了多个不同社区的节点，或者与同社区内其他节点的连接模式显著不同。通过社区检测模块，模型能够学习到这种结构异常模式，从而更准确地识别异常节点。此外，社区信息与节点特征的结合形成了更丰富的节点表示，增强了模型的表达能力，并有助于模型在未见过的图上更好地泛化。

### 图Transformer编码器

图Transformer编码器是GGADFormer的核心特征学习组件，采用Transformer架构来学习图中节点的表示。该模块通过多头注意力机制、前馈网络、层归一化和残差连接等组件，实现了对图数据的深度特征提取和表示学习。

多头注意力机制是该模块的核心组件，它通过Query、Key、Value三个线性变换将输入特征映射到不同的表示空间，然后计算注意力分数来衡量节点间的重要性关系。注意力计算过程遵循标准的缩放点积注意力公式，即Attention(Q,K,V) = softmax(QK^T/√d_k)V，其中d_k是Key的维度。多头设计允许模型同时关注不同的特征子空间，捕获更丰富的节点间关系模式。

前馈网络组件由两个线性变换层组成，中间使用GELU激活函数引入非线性。这个组件负责对注意力输出进行进一步的特征变换和增强。层归一化和残差连接则确保了训练的稳定性和梯度流动的顺畅性，使得模型能够训练更深的网络结构。

特征融合是该模块的重要功能，它将原始节点特征、多跳传播特征和社区嵌入特征进行拼接，形成包含多尺度信息的综合特征表示。这种融合策略确保了模型能够同时利用节点的固有属性、局部结构信息和全局社区信息，为后续的异常检测提供丰富的特征基础。

该模块的核心价值在于其强大的表示学习能力。多头注意力机制能够捕获图中任意两个节点间的关系，不受距离限制，这对于发现远距离的异常模式至关重要。注意力权重是自适应学习的，能够根据具体的图结构和任务需求调整节点间的重要性关系。此外，Transformer架构支持高效的并行计算，使得模型能够处理大规模图数据。多尺度特征融合确保了模型能够综合利用各种类型的信息，提高异常检测的准确性和鲁棒性。

### 异常生成器

异常生成器是GGADFormer的创新组件，专门负责基于正常节点生成高质量的合成异常样本。该模块的设计灵感来自于图异常检测中数据不平衡的挑战，通过智能的扰动生成策略，为模型提供多样化的异常样本用于训练。

该模块采用双路径扰动生成策略，包括全局扰动生成和局部扰动生成。全局扰动生成基于Transformer注意力机制，首先计算注意力加权的全局中心，该中心反映了图中所有节点对当前采样节点的重要性权重。然后，将采样节点的嵌入与注意力加权的全局中心进行拼接，输入到多层感知机中生成全局扰动。这种设计确保了生成的扰动能够反映全局的异常模式。

局部扰动生成则更加精细，它基于Transformer的注意力权重选择Top-K个最重要的邻居节点，然后对这些邻居的特征进行加权聚合，形成局部扰动。这种策略模拟了局部异常行为，即节点与其直接邻居的关系异常。通过结合全局和局部扰动，模型能够生成更加真实和多样化的异常样本。

异常样本的最终合成采用加权组合的方式，将原始正常样本与全局扰动相加，同时减去一定比例的局部扰动。这种设计确保了生成的异常样本既保持了与原始样本的关联性，又具有足够的异常特征。权重参数的选择经过精心调优，确保生成的样本既不会过于偏离原始样本而失去合理性，也不会过于接近原始样本而缺乏异常特征。

该模块的核心价值在于解决半监督学习中的数据不平衡问题。在现实应用中，异常样本往往稀少且难以获取，而正常样本相对充足。通过异常生成器，模型能够从有限的正常样本中生成多样化的异常样本，为判别器提供充足的训练数据。此外，生成的异常样本具有理论依据，基于注意力机制和邻居关系，确保了生成样本的合理性和有效性。这种设计不仅提高了模型的训练效果，还增强了模型对真实异常样本的泛化能力。

### 判别器

判别器是GGADFormer的输出组件，负责将学习到的节点表示转换为最终的异常检测结果。该模块采用简洁而有效的三层全连接网络结构，将高维的节点嵌入压缩为单一的异常分数，为异常检测任务提供最终的决策依据。

该模块的网络结构设计遵循渐进式特征压缩的原则，第一层将输入的高维特征压缩到一半维度，第二层进一步压缩到四分之一维度，最后一层输出单一的异常分数。这种设计既保证了足够的特征表达能力，又避免了过拟合问题。每层之间使用ReLU激活函数引入非线性变换，增强模型的表达能力。

判别器的输入是经过精心设计的特征组合，它将标记的正常节点表示与生成的异常节点表示进行拼接。这种设计确保了判别器能够同时学习正常模式和异常模式的特征，从而建立有效的决策边界。通过端到端的训练，判别器能够学习到最优的异常检测决策边界，最大化正常节点和异常节点的区分能力。

该模块的核心价值在于其简洁高效的设计和强大的判别能力。三层全连接结构确保了计算效率，使得模型能够快速进行推理。ReLU激活函数提供了必要的非线性表达能力，使得模型能够学习复杂的决策边界。端到端训练确保了判别器与整个网络的协同优化，学习到最适合异常检测任务的特征表示。输出的异常分数具有直观的可解释性，直接反映了节点的异常程度，便于实际应用中的决策制定。

# 损失函数设计

## 主要损失组件

### 二元交叉熵损失

二元交叉熵损失是GGADFormer的主要监督信号，负责训练判别器学习正常节点和异常节点的区分边界。该损失函数通过将标记的正常节点标签设为0，生成的异常节点标签设为1，为判别器提供明确的监督信息。损失函数还通过pos_weight参数处理类别不平衡问题，确保正负样本对训练的贡献得到平衡。

该损失的核心价值在于为整个网络提供主要的优化目标，指导模型学习有效的异常检测决策边界。通过最小化交叉熵损失，判别器能够逐渐学会区分正常模式和异常模式，为最终的异常检测任务奠定基础。

### 重构损失

重构损失专门用于控制异常生成器的输出质量，确保生成的异常样本与原始正常样本保持适当的距离。该损失通过计算生成异常样本与原始正常样本之间的欧几里得距离，约束异常生成的强度，防止生成的样本过于偏离原始样本而失去合理性。

该损失的重要意义在于保持生成样本的合理性，确保异常样本仍然具有图结构的相关性。通过控制异常生成的强度，模型能够生成既具有异常特征又保持图结构合理性的样本，为判别器提供高质量的训练数据。

### 对比学习损失

对比学习损失是GGADFormer的核心创新之一，它通过学习更好的特征表示空间来提高异常检测的性能。该损失通过计算正常节点与全局中心的相似度，以及正常节点与异常节点的相似度，建立对比学习的目标。温度参数用于控制相似度分布的尖锐程度，影响对比学习的强度。

该损失的核心价值在于学习更好的特征表示空间，使正常节点在特征空间中聚集，异常节点分散。通过对比学习，模型能够学习到更有判别性的特征表示，提高对异常模式的敏感性和区分能力。这种设计使得模型能够更好地捕获异常节点的特征模式。

### 社区引导损失

社区引导损失专门用于将社区结构信息融入节点表示学习过程，增强模型对图结构的理解能力。该损失通过计算节点表示与社区嵌入之间的均方误差，确保学习到的节点表示与社区结构保持一致。

该损失的重要意义在于增强模型对图结构的理解能力，提高模型在社区结构明显的图上的异常检测性能。通过社区引导，模型能够更好地理解节点的社区归属关系，从而更准确地识别与社区结构不符的异常节点。

## 总损失函数

总损失函数采用多目标优化的策略，将四个损失组件进行加权组合。这种设计确保了各个模块能够协同工作，共同优化异常检测性能。通过权重调整，可以控制不同损失组件的重要性，根据具体的应用场景和数据集特点进行优化。

该损失函数的核心价值在于平衡不同损失组件的贡献，确保模型能够同时学习到有效的特征表示、合理的异常生成、良好的判别能力和结构感知能力。这种多目标优化策略使得GGADFormer能够在多个方面都达到良好的性能。

# 训练策略

## 半监督学习设置

GGADFormer采用半监督学习策略，仅使用部分正常节点作为训练数据，通过异常生成器创建合成异常样本来解决数据不平衡问题。这种设置大大减少了对大量标注数据的依赖，降低了标注成本，同时提高了模型在实际应用中的实用性。

该策略的核心价值在于其现实可行性，在实际应用中，获取大量标注的异常样本往往困难且成本高昂，而正常样本相对容易获得。通过半监督学习，模型能够从有限的标注数据中学习到有效的异常检测模式，为实际部署提供了可行的解决方案。

## 学习率调度

GGADFormer采用多项式衰减的学习率调度策略，包含预热阶段和衰减阶段。预热阶段通过逐渐增加学习率避免训练初期的不稳定性，衰减阶段则通过多项式函数确保学习率平滑下降，避免训练过程中的震荡。

该策略的核心价值在于提高训练的稳定性和收敛性。预热阶段帮助模型在训练初期建立稳定的参数更新模式，衰减阶段则确保模型在训练后期能够精细调整参数，达到更好的性能。这种设计使得模型能够在整个训练过程中保持稳定的学习状态。

## 数据增强

GGADFormer通过向异常样本添加随机噪声来进行数据增强，提高模型对噪声的鲁棒性和泛化能力。这种策略通过增加训练数据的多样性，防止模型过拟合，同时提高模型在实际应用中对噪声数据的处理能力。

该策略的核心价值在于增强模型的鲁棒性和泛化能力。通过添加噪声，模型能够学习到更加鲁棒的特征表示，对输入数据的变化具有更强的适应性。这种设计使得模型能够在各种实际应用场景中保持稳定的性能。

# 评估指标

## 主要指标

GGADFormer使用AUC和AP两个主要指标来评估模型性能。AUC衡量模型的整体分类性能，通过ROC曲线下面积来量化模型区分正常和异常节点的能力。AP则考虑异常检测中的排序质量，更适合处理不平衡数据集，能够更好地反映模型在实际应用中的表现。

这两个指标的核心价值在于全面评估模型的异常检测能力。AUC提供了模型整体分类性能的评估，而AP则更关注异常检测任务中的排序质量，两者互补，能够从不同角度全面评估模型的性能表现。

## 评估过程

评估过程在完整的测试集上进行，通过计算模型输出的异常分数与真实标签之间的相关性来评估性能。这种评估方式确保了模型性能评估的客观性和可靠性，为模型的实际应用提供了可靠的性能指标。

该评估过程的核心价值在于提供客观可靠的性能评估，确保模型在实际部署前能够得到充分的验证。通过全面的性能评估，可以确保模型能够满足实际应用的需求。
